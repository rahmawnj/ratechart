<!DOCTYPE html>
<html lang="id">
<head>
  <meta charset="UTF-8" />
  <title>Deteksi Jari + Rope + FaceMesh + Suara</title>
  <style>
    body {
      margin: 0;
      background: #111;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
      overflow: hidden;
    }
    .container {
      position: relative;
      width: 640px;
      height: 480px;
    }
    video, canvas {
      position: absolute;
      width: 640px;
      height: 480px;
      top: 0;
      left: 0;
      border-radius: 10px;
      transform: scaleX(-1);
    }
    video {
      z-index: 0;
      opacity: 0.3;
    }
    #output_canvas {
      z-index: 1;
      pointer-events: none;
    }
  </style>
</head>
<body>
  <div class="container">
    <video id="input_video" playsinline></video>
    <canvas id="output_canvas" width="640" height="480"></canvas>
  </div>

  <!-- MediaPipe & Tone.js -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/tone@14.7.77/build/Tone.js"></script>

  <script>
    const videoElement = document.getElementById('input_video');
    const canvasElement = document.getElementById('output_canvas');
    const ctx = canvasElement.getContext('2d');

    // ============ MediaPipe Setup ============

    const hands = new Hands({ locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}` });
    hands.setOptions({ maxNumHands: 2, modelComplexity: 1, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });

    const faceMesh = new FaceMesh({ locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}` });
    faceMesh.setOptions({ maxNumFaces: 1, refineLandmarks: true, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });

    let latestHandsResults = null;
    let latestFaceResults = null;

    hands.onResults(results => latestHandsResults = results);
    faceMesh.onResults(results => latestFaceResults = results);

    const camera = new Camera(videoElement, {
      onFrame: async () => {
        await hands.send({ image: videoElement });
        await faceMesh.send({ image: videoElement });
      },
      width: 640,
      height: 480
    });
    camera.start();

    // ============ Tone.js Setup ============
    const synths = Array.from({ length: 5 }, () =>
      new Tone.Oscillator({ frequency: 440, type: 'sine', volume: -Infinity }).toDestination()
    );
    synths.forEach(s => s.start());

    // ============ Rope Simulation ============
    function createRope(start, end, numSegments = 50) {
      let points = [];
      for (let i = 0; i < numSegments; i++) {
        let t = i / (numSegments - 1);
        let x = start.x * (1 - t) + end.x * t;
        let y = start.y * (1 - t) + end.y * t;
        points.push({ pos: { x, y }, prev: { x, y } });
      }
      return {
        points,
        segmentLength: Math.hypot(end.x - start.x, end.y - start.y) / (numSegments - 1),
        movement: 0
      };
    }

    function updateRope(rope) {
      let totalMovement = 0;
      for (let i = 1; i < rope.points.length - 1; i++) {
        let p = rope.points[i];
        let vx = (p.pos.x - p.prev.x) * 0.98;
        let vy = (p.pos.y - p.prev.y) * 0.98;
        p.prev.x = p.pos.x;
        p.prev.y = p.pos.y;
        p.pos.x += vx;
        p.pos.y += vy;
        totalMovement += Math.hypot(vx, vy);
      }
      rope.movement = totalMovement / (rope.points.length - 2);
      for (let iter = 0; iter < 5; iter++) {
        for (let i = 0; i < rope.points.length - 1; i++) {
          let p1 = rope.points[i], p2 = rope.points[i + 1];
          let dx = p2.pos.x - p1.pos.x, dy = p2.pos.y - p1.pos.y;
          let dist = Math.hypot(dx, dy);
          let diff = (dist - rope.segmentLength) / dist;
          let offsetX = dx * 0.5 * diff;
          let offsetY = dy * 0.5 * diff;
          if (i !== 0) {
            p1.pos.x += offsetX;
            p1.pos.y += offsetY;
          }
          if (i !== rope.points.length - 1) {
            p2.pos.x -= offsetX;
            p2.pos.y -= offsetY;
          }
        }
      }
    }

    function drawRope(ctx, rope) {
      ctx.beginPath();
      ctx.moveTo(rope.points[0].pos.x, rope.points[0].pos.y);
      for (let i = 1; i < rope.points.length; i++) {
        ctx.lineTo(rope.points[i].pos.x, rope.points[i].pos.y);
      }
      ctx.strokeStyle = getColorFromMovement(rope.movement);
      ctx.lineWidth = 4;
      ctx.stroke();
      ctx.fillStyle = 'white';
      ctx.beginPath();
      ctx.arc(rope.points[0].pos.x, rope.points[0].pos.y, 5, 0, 2 * Math.PI);
      ctx.fill();
      ctx.beginPath();
      ctx.arc(rope.points[rope.points.length - 1].pos.x, rope.points[rope.points.length - 1].pos.y, 5, 0, 2 * Math.PI);
      ctx.fill();
    }

    function getColorFromMovement(m) {
      const clamped = Math.min(1, m / 5);
      const hue = 240 - 240 * clamped;
      return `hsl(${hue}, 100%, 50%)`;
    }

    function updateSound(index, rope) {
      const volume = Tone.gainToDb(Math.min(1, rope.movement / 10));
      const freq = Math.min(1000, 200 + (1000 / (rope.segmentLength + 1)));
      synths[index].volume.rampTo(volume, 0.05);
      synths[index].frequency.rampTo(freq, 0.1);
    }

    const fingerIndices = [4, 8, 12, 16, 20];
    let ropes = fingerIndices.map(() =>
      createRope({ x: -50, y: canvasElement.height / 2 }, { x: canvasElement.width + 50, y: canvasElement.height / 2 })
    );

    let idleTime = 0;

    function getIdleWiggle(t, baseX, baseY, amplitude = 300, freq = 0.0001) {
      const angle = t * freq + Math.random() * Math.PI * 2;
      const radius = amplitude * (0.5 + Math.random());
      return {
        x: baseX + Math.cos(angle) * radius,
        y: baseY + Math.sin(angle) * radius
      };
    }

    // ============ Main Render Loop ============
    function draw() {
      ctx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      ctx.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height);

      // Gambar wajah dulu (FaceMesh)
    // Ganti bagian draw() yang menggambar wajah jadi lebih ringan:
if (latestFaceResults?.multiFaceLandmarks?.length) {
  for (const landmarks of latestFaceResults.multiFaceLandmarks) {
    // Simpelkan jadi hanya garis oval dan topeng transparan
          // drawConnectors(ctx, landmarks, FACEMESH_FACE_OVAL, { color: '#FFFFFF', lineWidth: 2 });

    // const indices = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109];
    // ctx.beginPath();
    // let first = landmarks[indices[0]];
    // ctx.moveTo(first.x * canvasElement.width, first.y * canvasElement.height);
    // for (let i = 1; i < indices.length; i++) {
    //   let pt = landmarks[indices[i]];
    //   ctx.lineTo(pt.x * canvasElement.width, pt.y * canvasElement.height);
    // }
    // ctx.closePath();
              drawConnectors(ctx, landmarks, FACEMESH_TESSELATION, { color: '#FFFFFF', lineWidth: 6 });

    // ctx.fillStyle = 'rgba(0, 0, 0)';
    // ctx.fill();
    // Hapus drawConnectors dan drawLandmarks (opsional)
  }
}


      // Rope + tangan
      let leftHand = null, rightHand = null;
      if (latestHandsResults?.multiHandLandmarks && latestHandsResults.multiHandedness) {
        latestHandsResults.multiHandedness.forEach((hand, i) => {
          if (hand.label === "Left") leftHand = latestHandsResults.multiHandLandmarks[i];
          else if (hand.label === "Right") rightHand = latestHandsResults.multiHandLandmarks[i];
        });
      }

      idleTime++;

      ropes.forEach((rope, i) => {
        let leftTip = leftHand ? leftHand[fingerIndices[i]] : null;
        let rightTip = rightHand ? rightHand[fingerIndices[i]] : null;
        let start, end;
        const handsDetected = (leftHand ? 1 : 0) + (rightHand ? 1 : 0);

        if (handsDetected < 2) {
          let baseY = Math.random() * canvasElement.height;
          start = leftTip
            ? { x: leftTip.x * canvasElement.width, y: leftTip.y * canvasElement.height }
            : getIdleWiggle(idleTime + i * 100, -200, baseY);
          end = rightTip
            ? { x: rightTip.x * canvasElement.width, y: rightTip.y * canvasElement.height }
            : getIdleWiggle(idleTime + i * 200, canvasElement.width + 200, baseY);
        } else {
          start = { x: leftTip.x * canvasElement.width, y: leftTip.y * canvasElement.height };
          end = { x: rightTip.x * canvasElement.width, y: rightTip.y * canvasElement.height };
        }

        if (leftTip) rope.points[0].pos = { ...start };
        else rope.points[0] = { pos: { ...start }, prev: { ...start } };

        if (rightTip) rope.points[rope.points.length - 1].pos = { ...end };
        else rope.points[rope.points.length - 1] = { pos: { ...end }, prev: { ...end } };

        rope.segmentLength = Math.hypot(end.x - start.x, end.y - start.y) / (rope.points.length - 1);

        updateRope(rope);
        drawRope(ctx, rope);
        updateSound(i, rope);
      });

      requestAnimationFrame(draw);
    }

    // ============ Start Audio on Click ============
    document.body.addEventListener('click', async () => {
      await Tone.start();
      console.log('ðŸ”Š Audio started');
    });

    draw();
  </script>
</body>
</html>
