<!DOCTYPE html>
<html lang="id">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Deteksi Jari + Rope + Suara</title>
  <style>
    body {
      margin: 0;
      background: #111;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
      overflow: hidden;
    }
    .container {
      position: relative;
      width: 640px;
      height: 480px;
    }
   video,
canvas {
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%) scaleX(-1);
  object-fit: contain;

  max-width: 100vw;
  max-height: 100vh;
  width: auto;
  height: auto;
}

    video {
      z-index: 0;
      opacity: 0.3;
      filter: saturate(0.8);
    }
    #output_canvas {
      z-index: 1;
      pointer-events: none;
    }
  </style>
</head>
<body>
  <div class="container">
    <video id="input_video" playsinline></video>
    <canvas id="output_canvas" width="640" height="480"></canvas>
  </div>

  <!-- MediaPipe & Tone.js -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/tone@14.7.77/build/Tone.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>

  <script>
    const videoElement = document.getElementById('input_video');
    const canvasElement = document.getElementById('output_canvas');
    const ctx = canvasElement.getContext('2d');

    const hands = new Hands({ locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}` });
    hands.setOptions({ maxNumHands: 2, modelComplexity: 1, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });

    let latestHandsResults = null;
    hands.onResults(results => latestHandsResults = results);

const faceMesh = new FaceMesh({ locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}` });
faceMesh.setOptions({
  maxNumFaces: 1,
  refineLandmarks: true,
  minDetectionConfidence: 0.5,
  minTrackingConfidence: 0.5,
});

let latestFaceResults = null;
faceMesh.onResults(results => {
  latestFaceResults = results;
});

    const camera = new Camera(videoElement, {
      onFrame: async () => {
        await hands.send({ image: videoElement });
          await faceMesh.send({ image: videoElement });

      },
     
    });
    camera.start();



    function createRope(start, end, numSegments = 20) {
      let points = [];
      for (let i = 0; i < numSegments; i++) {
        let t = i / (numSegments - 1);
        let x = start.x * (1 - t) + end.x * t;
        let y = start.y * (1 - t) + end.y * t;
        points.push({ pos: { x, y }, prev: { x, y } });
      }
      return {
        points,
        segmentLength: Math.hypot(end.x - start.x, end.y - start.y) / (numSegments - 1),
        movement: 0
      };
    }

    function updateRope(rope) {
      let totalMovement = 0;
      for (let i = 1; i < rope.points.length - 1; i++) {
        let p = rope.points[i];
        let vx = (p.pos.x - p.prev.x) * 0.98;
        let vy = (p.pos.y - p.prev.y) * 0.98;
        p.prev.x = p.pos.x;
        p.prev.y = p.pos.y;
        p.pos.x += vx;
        p.pos.y += vy;
        totalMovement += Math.hypot(vx, vy);
      }
      rope.movement = totalMovement / (rope.points.length - 2);
      for (let iter = 0; iter < 10; iter++) {
        for (let i = 0; i < rope.points.length - 1; i++) {
          let p1 = rope.points[i], p2 = rope.points[i + 1];
          let dx = p2.pos.x - p1.pos.x, dy = p2.pos.y - p1.pos.y;
          let dist = Math.hypot(dx, dy);
          let diff = (dist - rope.segmentLength) / dist;
          let offsetX = dx * 0.5 * diff;
          let offsetY = dy * 0.5 * diff;
          if (i !== 0) {
            p1.pos.x += offsetX;
            p1.pos.y += offsetY;
          }
          if (i !== rope.points.length - 1) {
            p2.pos.x -= offsetX;
            p2.pos.y -= offsetY;
          }
        }
      }
    }
// 1. Efek: Reverb + Chorus + Filter
const reverb = new Tone.Reverb({ decay: 3, wet: 0.4 }).toDestination();
const chorus = new Tone.Chorus(4, 2.5, 0.5).connect(reverb);
const filter = new Tone.Filter(800, "lowpass").connect(chorus);


const synths = Array.from({ length: 5 }, (_, i) =>
  new Tone.Oscillator({
    frequency: 440 + i * 15, // kasih variasi frekuensi sedikit
    type: 'triangle',        // lebih lembut dari sine kalau barengan
    volume: -20              // volume lebih rendah dari -Infinity
  }).toDestination()
);
synths.forEach(s => s.start());

// 2. PolySynth dengan envelope
const poly = new Tone.PolySynth(Tone.Synth, {
  maxPolyphony: 5,
  volume: -8,
  oscillator: { type: "sawtooth" },
  envelope: {
    attack: 0.1,
    decay: 0.2,
    sustain: 0.5,
    release: 1
  }
}).connect(filter);

// Mulai synth
poly.set({ detune: -120 }); // sedikit detune biar kaya

    function drawRope(ctx, rope) {
      ctx.beginPath();
      ctx.moveTo(rope.points[0].pos.x, rope.points[0].pos.y);
      for (let i = 1; i < rope.points.length; i++) {
        ctx.lineTo(rope.points[i].pos.x, rope.points[i].pos.y);
      }
      ctx.strokeStyle = getColorFromMovement(rope.movement);
      ctx.lineWidth = 4;
      ctx.stroke();
      ctx.fillStyle = 'white';
      ctx.beginPath();
      ctx.arc(rope.points[0].pos.x, rope.points[0].pos.y, 5, 0, 2 * Math.PI);
      ctx.fill();
      ctx.beginPath();
      ctx.arc(rope.points[rope.points.length - 1].pos.x, rope.points[rope.points.length - 1].pos.y, 5, 0, 2 * Math.PI);
      ctx.fill();
    }

    function getColorFromMovement(m) {
      const clamped = Math.min(1, m / 5);
      const hue = 240 - 240 * clamped;
      return `hsl(${hue}, 100%, 50%)`;
    }

   // definisikan skala pentatonik C mayor
const pentatonic = ["C4","D4","E4","G4","A4","C5"];

function updateSound(index, rope) {
  // 1) normalisasi movement jadi 0â€“1
  const mNorm = Math.min(1, rope.movement / 10);

  // 2) pilih note dari skala pentatonik
  const scaleIndex = Math.floor(mNorm * (pentatonic.length - 1));
  const note = pentatonic[scaleIndex];

  // 3) velocity lembut
  const velocity = 0.1 + 0.6 * mNorm; 

  // 4) jika merah (mNorm > 0.8), pakai durasi lebih panjang & triangle wave
  let duration = "16n";
  if (mNorm > 0.8) {
    duration = "4n";
    poly.set({ oscillator: { type: "triangle" } });
    reverb.wet.rampTo(0.7, 0.2);
  } else {
    poly.set({ oscillator: { type: "sawtooth" } });
    reverb.wet.rampTo(0.4, 0.2);
  }

  // 5) trigger dengan envelope polySynth yang sudah kita definisikan
  poly.triggerAttackRelease(note, duration, undefined, velocity);

  // 6) buka filter cutoff sedikit sesuai movement
  const cutoff = 500 + mNorm * 2500;  // 500Hz â†’ 3000Hz
  filter.frequency.rampTo(cutoff, 0.1);
}

    const fingerIndices = [4, 8, 12, 16, 20];
    let ropes = fingerIndices.map(() =>
      createRope({ x: -50, y: canvasElement.height / 2 }, { x: canvasElement.width + 50, y: canvasElement.height / 2 })
    );

    let idleTime = 0;

    function getIdleWiggle(t, baseX, baseY, amplitude = 300, freq = 0.0001) {
      const angle = t * freq + Math.random() * Math.PI * 2;
      const radius = amplitude * (0.5 + Math.random());
      return {
        x: baseX + Math.cos(angle) * radius,
        y: baseY + Math.sin(angle) * radius
      };
    }

    function draw() {
      ctx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      ctx.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height);

      let leftHand = null, rightHand = null;
      if (latestHandsResults?.multiHandLandmarks && latestHandsResults.multiHandedness) {
        latestHandsResults.multiHandedness.forEach((hand, i) => {
          if (hand.label === "Left") leftHand = latestHandsResults.multiHandLandmarks[i];
          else if (hand.label === "Right") rightHand = latestHandsResults.multiHandLandmarks[i];
        });
      }
      if (latestFaceResults?.multiFaceLandmarks) {
  for (const landmarks of latestFaceResults.multiFaceLandmarks) {
    drawConnectors(ctx, landmarks, FACEMESH_TESSELATION, { color: 'black', lineWidth: 6 });
    // drawConnectors(ctx, landmarks, FACEMESH_RIGHT_EYE, { color: '#FF0000' });
    // drawConnectors(ctx, landmarks, FACEMESH_LEFT_EYE, { color: '#0000FF' });
    // drawConnectors(ctx, landmarks, FACEMESH_FACE_OVAL, { color: '#FFFFFF' });
  }
}


      idleTime++;

      ropes.forEach((rope, i) => {
        let leftTip = leftHand ? leftHand[fingerIndices[i]] : null;
        let rightTip = rightHand ? rightHand[fingerIndices[i]] : null;
        let start, end;
        const handsDetected = (leftHand ? 1 : 0) + (rightHand ? 1 : 0);

        if (handsDetected < 2) {
          let baseY = Math.random() * canvasElement.height;
          start = leftTip
            ? { x: leftTip.x * canvasElement.width, y: leftTip.y * canvasElement.height }
            : getIdleWiggle(idleTime + i * 100, -200, baseY);
          end = rightTip
            ? { x: rightTip.x * canvasElement.width, y: rightTip.y * canvasElement.height }
            : getIdleWiggle(idleTime + i * 200, canvasElement.width + 200, baseY);
        } else {
          start = { x: leftTip.x * canvasElement.width, y: leftTip.y * canvasElement.height };
          end = { x: rightTip.x * canvasElement.width, y: rightTip.y * canvasElement.height };
        }

        if (leftTip) rope.points[0].pos = { ...start };
        else rope.points[0] = { pos: { ...start }, prev: { ...start } };

        if (rightTip) rope.points[rope.points.length - 1].pos = { ...end };
        else rope.points[rope.points.length - 1] = { pos: { ...end }, prev: { ...end } };

        rope.segmentLength = Math.hypot(end.x - start.x, end.y - start.y) / (rope.points.length - 1);

        updateRope(rope);
        drawRope(ctx, rope);
        updateSound(i, rope);
      });

      requestAnimationFrame(draw);
    }

    document.body.addEventListener('click', async () => {
      await Tone.start();
      console.log('ðŸ”Š Audio started');
    });

    draw();
    videoElement.addEventListener('loadedmetadata', () => {
  resizeToVideo();
});

function resizeToVideo() {
  const aspectRatio = videoElement.videoWidth / videoElement.videoHeight;

  // Ambil ukuran layar
  const screenWidth = window.innerWidth;
  const screenHeight = window.innerHeight;

  // Hitung ukuran ideal agar tidak stretching
  let width = screenWidth;
  let height = width / aspectRatio;

  if (height > screenHeight) {
    height = screenHeight;
    width = height * aspectRatio;
  }

  // Apply ke elemen
  videoElement.style.width = width + 'px';
  videoElement.style.height = height + 'px';
  canvasElement.style.width = width + 'px';
  canvasElement.style.height = height + 'px';

  // Juga sesuaikan ukuran internal canvas (agar gambar jelas)
  canvasElement.width = videoElement.videoWidth;
  canvasElement.height = videoElement.videoHeight;
}

  </script>
</body>
</html>
