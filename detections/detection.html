<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>MediaPipe Face Mesh Detection</title>
  <!-- Sertakan library MediaPipe Face Mesh, camera dan drawing utils -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: #000;
      display: flex;
      align-items: center;
      justify-content: center;
      height: 100vh;
    }
    .container {
      position: relative;
      width: 100%;
      max-width: 640px;
    }
    video {
      width: 100%;
      display: block;
      object-fit: contain;
      transform: scaleX(-1); /* Mirror video */
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
      transform: scaleX(-1); /* Mirror canvas overlay */
    }
  </style>
</head>
<body>
  <div class="container">
    <video id="video" autoplay playsinline></video>
    <canvas id="output"></canvas>
  </div>

  <script>
    const videoElement = document.getElementById('video');
    const canvasElement = document.getElementById('output');
    const canvasCtx = canvasElement.getContext('2d');

    async function setupCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: 'user' }
      });
      videoElement.srcObject = stream;
      return new Promise(resolve => {
        videoElement.onloadedmetadata = () => {
          resolve(videoElement);
        };
      });
    }

    function adjustCanvasSize() {
      canvasElement.width = videoElement.videoWidth;
      canvasElement.height = videoElement.videoHeight;
    }
    videoElement.addEventListener('loadedmetadata', adjustCanvasSize);
    window.addEventListener('resize', adjustCanvasSize);

    // Inisialisasi Face Mesh
    const faceMesh = new FaceMesh({
      locateFile: (file) =>
        `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
    });
    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    faceMesh.onResults((results) => {
      // Bersihkan canvas setiap frame
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

      if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
        for (const landmarks of results.multiFaceLandmarks) {
          // Gambar konektor dan landmark wajah secara default
          drawConnectors(canvasCtx, landmarks, FACEMESH_TESSELATION, { color: '#FFFFFF', lineWidth: 1 });
          drawConnectors(canvasCtx, landmarks, FACEMESH_FACE_OVAL, { color: '#FFFFFF', lineWidth: 2 });
          drawLandmarks(canvasCtx, landmarks, { color: '#FFFFFF', lineWidth: 1 });

          // Contoh: Gambar topeng solid di atas area wajah (misal: masker dengan opacity)
          // Kita menggunakan indeks wajah untuk menentukan area masker. 
          // Indeks berikut merupakan contoh (misal: mengikuti kontur wajah).
          const faceOvalIndices = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109];
          canvasCtx.beginPath();
          let firstPoint = landmarks[faceOvalIndices[0]];
          canvasCtx.moveTo(firstPoint.x * canvasElement.width, firstPoint.y * canvasElement.height);
          for (let i = 1; i < faceOvalIndices.length; i++) {
            let point = landmarks[faceOvalIndices[i]];
            canvasCtx.lineTo(point.x * canvasElement.width, point.y * canvasElement.height);
          }
          canvasCtx.closePath();
          canvasCtx.fillStyle = 'rgba(0, 0, 0, 0.5)'; // Ubah opacity sesuai kebutuhan
          canvasCtx.fill();
        }
      }
    });

    // Menggunakan objek Camera dari MediaPipe untuk mendapatkan frame video
    const camera = new Camera(videoElement, {
      onFrame: async () => {
        await faceMesh.send({ image: videoElement });
      }
    });

    setupCamera().then(() => {
      camera.start();
    });
  </script>
</body>
</html>
